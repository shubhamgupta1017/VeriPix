{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "240cae38-e80d-4409-9b5e-b297fef2e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "# File path to your JSON file\n",
    "file_path = 'output/84_task1.json'\n",
    "\n",
    "# Load JSON data from the file\n",
    "with open(file_path, 'r') as file:\n",
    "    parsed_data = json.load(file)\n",
    "\n",
    "# Find indices where prediction is \"fake\"\n",
    "fake_indices = [item['index'] for item in parsed_data if item['prediction'] == \"fake\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3618b764-fe3b-4f95-8d6d-9b464c5f2648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (4.47.0)\n",
      "Requirement already satisfied: filelock in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: torch in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (2.5.0)\n",
      "Requirement already satisfied: filelock in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: networkx in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: accelerate>=0.26.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (1.1.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from accelerate>=0.26.0) (0.26.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from accelerate>=0.26.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from accelerate>=0.26.0) (23.2)\n",
      "Requirement already satisfied: psutil in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from accelerate>=0.26.0) (5.9.6)\n",
      "Requirement already satisfied: pyyaml in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from accelerate>=0.26.0) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from accelerate>=0.26.0) (0.4.5)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from accelerate>=0.26.0) (2.5.0)\n",
      "Requirement already satisfied: filelock in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2024.10.0)\n",
      "Requirement already satisfied: requests in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.26.0) (4.8.0)\n",
      "Requirement already satisfied: networkx in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from torch>=1.10.0->accelerate>=0.26.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate>=0.26.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.26.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/user1/miniconda3/envs/tf/lib/python3.9/site-packages (from requests->huggingface-hub>=0.21.0->accelerate>=0.26.0) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers\n",
    "!pip install torch\n",
    "!pip install 'accelerate>=0.26.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589c72d9-4983-44e9-95d2-7c89664a787e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 17:01:50.496588: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-12-06 17:01:50.496717: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-12-06 17:01:50.496750: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-06 17:01:50.505673: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-12-06 17:01:51.293243: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02b5b04f53654226a06e4bd8e0b8eeb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import requests\n",
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
    "token = \"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\"  # replace with your actual Hugging Face API token\n",
    "\n",
    "# Load the model with the token for authentication\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",  # This automatically uses multiple GPUs if available, can change to None if you want to specify a single GPU.\n",
    "    token=token  # API token for Hugging Face authentication\n",
    ")\n",
    "\n",
    "# Load the processor with the token for authentication\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    model_id,\n",
    "    token=token  # API token for Hugging Face authentication\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97596123-5b9b-46ac-951d-582f5c150f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# Set device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "053639f1-cae3-48bb-bb99-244a4fa2792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torchvision import models, transforms\n",
    "# from torch.utils.data import DataLoader, Dataset\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Step 1: Load the Pre-trained ResNet-18 Model\n",
    "# classifier = models.densenet121(pretrained=True)\n",
    "\n",
    "# # Step 2: Modify the final fully connected layer for binary classification (10 output)\n",
    "# classifier.classifier = nn.Sequential(\n",
    "#     nn.Linear(classifier.classifier.in_features, 10),   # Change the output to 10 unit\n",
    "# )\n",
    "\n",
    "# classifier.load_state_dict(torch.load('../classify-10/densenet121_classify10_weights.pth', map_location = device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd792d98-94fb-49e1-863c-d6bff66ece4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Initialize the data structure\n",
    "json_data = []\n",
    "\n",
    "# Function to add an entry\n",
    "def add_to_json(json_data, index, artifact_name, explanation):\n",
    "    # Check if the index already exists\n",
    "    for entry in json_data:\n",
    "        if entry['index'] == index:\n",
    "            # Add the artifact and explanation\n",
    "            entry['explanation'][artifact_name] = explanation\n",
    "            return json_data\n",
    "    \n",
    "    # If index doesn't exist, create a new entry\n",
    "    json_data.append({\n",
    "        \"index\": index,\n",
    "        \"explanation\": {artifact_name: explanation}\n",
    "    })\n",
    "    return json_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46235356-e2a4-47f4-90d5-c3638d686f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "unnatural_colors = [\"blue\", \"magenta\", \"pink\", \"purple\", \"cyan\"]\n",
    "\n",
    "def extract_ans(prompt, image, obj, index):\n",
    "    global json_data\n",
    "    \n",
    "    is_child_prompt = False\n",
    "    answers = []\n",
    "    \n",
    "    for sub_prompt in prompt:\n",
    "        # Set the seed\n",
    "        seed = 10\n",
    "        \n",
    "        # Ensure reproducibility\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "        print(\"Prompt: \", sub_prompt)\n",
    "        messages = [\n",
    "            {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"image\"},\n",
    "              #  {\"type\": \"text\", \"text\": \"Is the heatmap red part concentrated on the 'face','body' or 'background'? Answer in one word.\"}\n",
    "                {\"type\": \"text\", \"text\": sub_prompt}\n",
    "            ]}\n",
    "        ]\n",
    "        input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "        # Process the input, ensure the inputs are on the same device as the model\n",
    "        inputs = processor(\n",
    "            image,\n",
    "            input_text,\n",
    "            add_special_tokens=False,\n",
    "            return_tensors=\"pt\"\n",
    "        ).to(model.device)\n",
    "        \n",
    "        output = model.generate(**inputs, max_new_tokens=4, temperature=0.7)\n",
    "\n",
    "        text = processor.decode(output[0])\n",
    "            \n",
    "        lines = text.strip().splitlines()\n",
    "        # Access the last line\n",
    "        last_line = lines[-1]\n",
    "        end = min(last_line.find(\".\"), last_line.find(\"<\"))\n",
    "        line = last_line[0:end].lower()\n",
    "        if \"yes\" in line:\n",
    "            ans = \"yes\"\n",
    "        elif \"no\" in line:\n",
    "            ans = \"no\"\n",
    "        else:\n",
    "            ans = ''.join([char for char in line if char.isalpha() or char.isspace()])\n",
    "\n",
    "        print(\"Answer: \", ans)\n",
    "\n",
    "        if index != -1:\n",
    "            answers.append(ans)\n",
    "            \n",
    "        if ans != \"yes\":\n",
    "            break\n",
    "    # for answer in answers:\n",
    "    #     if answer != \"yes\":\n",
    "    #         if answer in unnatural_colors:\n",
    "    #             if obj == \"bird\":\n",
    "    #                 explanation = get_explanations(artifact, obj, \"beak\", ans)\n",
    "    #             else:\n",
    "    #                 explanation = get_explanations(artifact, obj, \"body\", ans)\n",
    "    #         else:\n",
    "    #             explanation = get_explanations(artifact, obj, ans, \"NULL\")\n",
    "    \n",
    "    #         json_data = add_to_json(json_data, index, artifact, explanation)\n",
    "    final_ans = ans\n",
    "    if index == -1 or final_ans == \"no\" or final_ans == \"none\":\n",
    "        return final_ans\n",
    "\n",
    "\n",
    "    artifact = prompt_to_artifact(obj, prompt[0])\n",
    "    if artifact == \"Incorrect skin tones\":\n",
    "        if final_ans in unnatural_colors:\n",
    "            if obj == \"bird\":\n",
    "                explanation = get_explanations(artifact, obj, \"beak\", final_ans)\n",
    "            else:\n",
    "                explanation = get_explanations(artifact, obj, \"body\", final_ans)\n",
    "        else:\n",
    "            return final_ans\n",
    "    elif final_ans != \"yes\":\n",
    "        explanation = get_explanations(artifact, obj, final_ans, \"NULL\")\n",
    "    else:\n",
    "        explanation = get_explanations(artifact, obj, \"NULL\", \"NULL\")\n",
    "\n",
    "    json_data = add_to_json(json_data, index, artifact, explanation)        \n",
    "    \n",
    "    return final_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a1595b8-b34b-49cd-890d-457fa8e6e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_to_artifact(obj, prompt):\n",
    "    mapping = {\n",
    "        common_prompts[0][0] : \"Unnatural Lighting Gradients\",\n",
    "        common_prompts[1][0] : \"Glow or light bleed around object boundaries\",\n",
    "        common_prompts[2][0] : \"Texture repetition patterns\",\n",
    "        common_prompts[3][0] : \"Unrealistic specular highlights\",\n",
    "\n",
    "        animal_prompts[1][0] : \"Incorrect skin tones\",\n",
    "        \n",
    "        prompts['airplane'][0][0]: \"Implausible aerodynamic structures\",\n",
    "        prompts['airplane'][1][0]: \"Misaligned body panels\",\n",
    "        prompts['airplane'][2][0]: \"Inconsistent scale of mechanical parts\",\n",
    "        prompts['airplane'][3][0]: \"Abruptly cut off objects\",\n",
    "        \n",
    "        prompts['car'][0][0]:\"Incorrect wheel geometry\",\n",
    "        prompts['car'][1][0]: \"Misaligned body panels\",\n",
    "    \n",
    "        prompts['truck'][0][0]: \"Incorrect wheel geometry\",\n",
    "        prompts['truck'][1][0]: \"Misaligned body panels\",\n",
    "    \n",
    "        prompts['ship'][0][0]: \"Misaligned body panels\",\n",
    "        prompts['ship'][1][0]: \"Inconsistent scale of mechanical parts\",\n",
    "        prompts['ship'][2][0]: \"Incorrect reflection mapping\",\n",
    "        \n",
    "        prompts['cat-face'][0][0]: \"Misaligned bilateral elements in animal faces\",\n",
    "        prompts['cat-face'][1][0]: \"Misshapen ears or appendages\",\n",
    "        prompts['cat-face'][2][0]: \"Blurred boundaries in fine details\",\n",
    "        prompts['cat-body'][0][0]: \"Abruptly cut off objects\",\n",
    "        prompts['cat-body'][1][0]: \"Floating or disconnected components\",\n",
    "        prompts['cat-body'][2][0]: \"Anatomically incorrect paw structures\",\n",
    "        prompts['cat-body'][3][0]: \"Scale inconsistencies within same objects\",\n",
    "        \n",
    "        prompts['dog-face'][0][0]:\"Misaligned bilateral elements in animal faces\",\n",
    "        prompts['dog-face'][1][0]: \"Misshapen ears or appendages\",\n",
    "        prompts['dog-face'][2][0]: \"Blurred boundaries in fine details\",\n",
    "        prompts['dog-body'][0][0]: \"Abruptly cut off objects\",\n",
    "        prompts['dog-body'][1][0]: \"Floating or disconnected components\",\n",
    "        prompts['dog-body'][2][0]: \"Anatomically incorrect paw structures\",\n",
    "        prompts['dog-body'][3][0]: \"Scale inconsistencies within single objects\",\n",
    "        \n",
    "        prompts['horse-face'][0][0]: \"Misaligned bilateral elements in animal faces\",\n",
    "        prompts['horse-face'][1][0]: \"Misshapen ears or appendages\",\n",
    "        prompts['horse-face'][2][0]: \"Blurred boundaries in fine details\",\n",
    "        \n",
    "        prompts['horse-body'][0][0]: \"Anatomically impossible joint configurations\",\n",
    "        prompts['horse-body'][1][0]: \"Abruptly cut off objects\",\n",
    "        prompts['horse-body'][2][0]: \"Floating or disconnected components\",\n",
    "        prompts['horse-body'][3][0]: \"Scale inconsistencies within single objects\",\n",
    "        \n",
    "        prompts['deer-face'][0][0]: \"Misaligned bilateral elements in animal faces\",\n",
    "        prompts['deer-face'][1][0]: \"Misshapen ears or appendages\",\n",
    "        prompts['deer-face'][2][0]: \"Blurred boundaries in fine details\",\n",
    "        prompts['deer-body'][0][0]: \"Anatomically impossible joint configurations\",\n",
    "        prompts['deer-body'][1][0]: \"Abruptly cut off objects\",\n",
    "        prompts['deer-body'][2][0]: \"Scale inconsistencies within single objects\",\n",
    "        \n",
    "        prompts['bird'][0][0]: \"Misaligned bilateral elements in animal faces\",\n",
    "        prompts['bird'][1][0]: \"Incorrect skin tones\",\n",
    "        prompts['frog'][0][0]: \"Anatomically impossible joint configurations\",\n",
    "        prompts['frog'][1][0]: \"Unnaturally glossy surfaces\",\n",
    "    \n",
    "    }\n",
    "    return mapping[prompt]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f55c65f4-a0d6-46c9-9ae6-291f0b57e7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_explanations(artifact, obj, feature, color):\n",
    "    artifact_explanations = {\n",
    "        \"Blurred boundaries in fine details\": f\"The eyes, nose and mouth of the {obj} are not easily seperatable, caused due to blurriness in the fine details of the face\",\n",
    "        \"Floating or disconnected components\": f\"Parts of the {obj} appear to float unnaturally.\",\n",
    "        \"Asymmetric features in naturally symmetric objects\": f\"The {obj}'s features are uneven or misaligned, making it look unnatural.\",\n",
    "        \"Misaligned bilateral elements in animal faces\": f\"{feature} of the {obj}, are misaligned or asymmetrical.\",\n",
    "        \"Texture bleeding between adjacent regions\": f\"Textures of different regions of the {obj} are not well seperated, and seem to bleed into one another.\",\n",
    "        \"Texture repetition patterns\": \"Identical patterns appear unnaturally repeated on surfaces\",\n",
    "        \"Unrealistic specular highlights\": f\"The {obj} shines on one side of its body, despite no direct light being incident on that side, which shows artificial nature of the image.\",\n",
    "        \"Anatomically incorrect paw structures\": f\"The {obj}'s paws have incorrect shapes or structures.\",\n",
    "        \"Misshapen ears or appendages\": f\"The {obj}'s ears have distorted or unusual shapes.\",\n",
    "        \"Impossible mechanical connections\": f\"Connections between parts of the {obj} defy physics or engineering principles.\",\n",
    "        \"Inconsistent scale of mechanical parts\": f\"{feature} of the {obj} appears at incorrect scales relative to the rest of the {obj}.\",\n",
    "        \"Physically impossible structural elements\": f\"The {obj} has structures that would collapse in reality.\",\n",
    "        \"Incorrect reflection mapping\": f\"The {obj}'s reflection doesn't match its own figure unlike in real world reflections.\",\n",
    "        \"Scale inconsistencies within single objects\": f\"The {feature} of the {obj} is unnaturally sized as compared to the rest of the body.\",\n",
    "        \"Incorrect wheel geometry\": f\"The wheels appear misshapen or distorted.\",\n",
    "        \"Implausible aerodynamic structures\": \"The airplane's wings and other components are not aerodynamically viable, unlike those of a real aircraft.\",\n",
    "        \"Misaligned body panels\": f\"the {obj}'s {feature} appear offset from their usual positions as in corresponding real {obj}\",\n",
    "        \"Anatomically impossible joint configurations\": f\"The {obj} joints bend in directions that are physically impossible.\",\n",
    "        \"Repeated element patterns\": \"The same feature, like a tree, appears unnaturally duplicated in the scene.\",\n",
    "    \n",
    "        \"Incorrect skin tones\": f\"The {obj}'s {feature} is {color} in color, which is very uncommon in actual real life {obj}s\",\n",
    "    \n",
    "        \"Unnatural color transitions\": \"Color changes appear harsh and unrealistic.\",\n",
    "        \"Unnatural Lighting Gradients\": f\"The {obj} looks artificial amidst the unnatural lighting gradient visible in the background.\",\n",
    "        \"Abruptly cut off objects\": f\"Parts of the {obj} are visibly truncated, as if cropped.\",\n",
    "        \"Glow or light bleed around object boundaries\": f\"Bright halos appear around the boundaries of the {obj}, disrupting natural lighting.\",\n",
    "        \"Cinematization Effects\": f\"The {obj} has high contrast, which resembles beautification of the character as in movies.\",\n",
    "        \"Movie-poster-like composition of ordinary scenes\": \"The background appears unnaturally bright, with a striking contrast reminiscent of cinematic lighting.\",\n",
    "        \"Artificial smoothness\": \"The background of the images appear overly smoothened, losing natural texture.\",\n",
    "        \"Unnaturally glossy surfaces\": f\"The {obj}'s body seems to shine like a metallic surface, which should not be the case owing to its skin's natural nature.\",\n",
    "        # \"Scale inconsistencies within the same object class\": f\"{obj}'s have mismatched sizes in the same image.\"\n",
    "        \"Scale inconsistencies within single objects\": f\"Certain parts of the {obj} exhibit unnatural size proportions, which disrupt the overall balance and make the design appear less realistic.\"\n",
    "    }\n",
    "    return artifact_explanations[artifact]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9be09d25-391b-4ea8-8405-388107c7abb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class_list = [ 'airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "transform = transforms.Compose([\n",
    "  transforms.Resize((224, 224)),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize for ImageNet\n",
    "])\n",
    "\n",
    "common_prompts = []\n",
    "animal_prompts = []\n",
    "\n",
    "def classify_obj(image):\n",
    "    global common_prompts, animal_prompts\n",
    "    # image = torch.unsqueeze(transform(image), dim = 0)\n",
    "\n",
    "    # outputs = classifier(image)  # Forward pass\n",
    "    # # print(outputs.shape)\n",
    "    # _, pred_label = torch.max(outputs, 1)\n",
    "\n",
    "    obj = extract_ans([\"Classify the image into one of 'airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck'. If neither, say 'others'. Answer in one word.\"], image, \"\", -1).lower()\n",
    "    \n",
    "    # obj = class_list[pred_label]\n",
    "    \n",
    "    common_prompts = [\n",
    "        [f\"You are an artificial image artifact detector. This is a deepfake image of a {obj}. Does the 'background' show clearly a very smooth color gradient? Say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [f\"You are an artificial image artifact detector. This is a deepfake image of a {obj}. Does the image show Light Glowing around the boundary of the {obj}? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [f\"You are an artificial image artifact detector. This is a deepfake image of a {obj}. Do you see identical patterns appear unnaturally repeated on surfaces. Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [f\"You are an artificial image artifact detector. This is a deepfake image of a {obj}. Is the {obj} shining on the side light is not incident on it? Say 'yes' or 'no'. Answer in one word.\"]\n",
    "    ]\n",
    "    \n",
    "    animal = \"NONE\"\n",
    "    if obj in ['cat', 'deer', 'dog', 'horse']:\n",
    "        animal = obj\n",
    "        animal_prompts = [\n",
    "            [f\"You are an artificial image artifact detector. This is a deepfake image of a {animal}. Is the annotated part of the image centered on the 'body' or 'face' of the {animal}? Answer in one word.\"],\n",
    "            [f\"You are an artificial image artifact detector. This is a deepfake image of a {animal}. Specify the {animal}'s color. Answer in one word.\"]\n",
    "        ]\n",
    "\n",
    "\n",
    "    return obj\n",
    "\n",
    "prompts = {\n",
    "    'airplane': [\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of an airplane. Can you tell me if this image contains Implausible Aerodynamic Structures? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of an airplane. Can you tell me if this image contains Misaligned Body Panels? Simply say 'yes' or 'no'. Answer in one word.\", \"Image shows deepfake of an airplane. Which airplane mechanical part is positioned 'wrongly' in the image? Say 'none' is everything is ok. Answer in one word.\"],\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of an airplane. Are different airplane mechanical parts out of proportion in size? Simply say 'yes' or 'no'. Answer in one word.\", \"Image shows deepfake of an airplane. Check all four options before answering. Out of 'wings', 'tail', 'wheels', 'engines', which one is not of correct size? Answer in one word by choosing one.\"],\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of an airplane. Does any part of the airplane abruptly end within the image? Simply say 'yes' or 'no'. Answer in one word.\", \"Image shows deepfake of an airplane. Which airplane mechanical part is abruptly cut off in the middle of the image? Say 'none' if all are ok. Answer in one word.\"] #Check all threr options before answering. Out of 'wings', 'tail', 'fuselage', which one is not complete? Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'car': [\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of a car. Are there issues with the wheel structure? Simply say 'yes' or 'no'. Say 'no' if not visible. If wheel is not visible completely, say 'no'. Answer in one word.\"],\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of a car. Can you tell me if this image contains Misaligned Body Panels? Simply say 'yes' or 'no'.\", \"Image shows deepfake of a car. Check all four options before answering. Out of 'headlights', 'tail lights', 'rear view mirror', 'door', which one has some error in it? Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'truck': [\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of a truck. Are there issues with the wheel structure? Simply say 'yes' or 'no'. If wheel is not visible completely, say 'no'. Answer in one word.\"],\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of a truck. Can you tell me if this image contains Misaligned Body Panels? Simply say 'yes' or 'no'. Answer in one word.\", \"Image shows deepfake of a truck. Check all four options before answering. Out of 'headlights', 'tail lights', 'rear view mirror', 'door', which one has some error in it? Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'ship': [\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of a ship. Does the image contain Misaligned Body Panels? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of a ship. Does the image contain Inconsistent Scale of Mechanical Parts? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of a ship. If the image shows the ship's reflection, is it symmetric with respect to the ship? Simply say 'yes' or 'no'. Say 'no' if no reflection. Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'cat-face': [\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of a cat. Does the image contain Asymmetry in the cat's facial features? Simply say 'yes' or 'no'.  If only one side of face is visible, say 'no'. Answer in one word.\", \"Image shows deepfake of a cat. Check all four options before answering. Out of 'eyes', 'ears', 'nose', 'mouth', which one is not symmetrical? Answer in one word by choosing one.\"],\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of a cat. Are the ears like a normal cat? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [\"You are an artificial image artifact detector. This is a deepfake image of a cat. Are the eyes, nose, and mouth clearly distinguishable from each other? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'cat-body': [\n",
    "        [\"Image shows deepfake of a cat. Check all three before choosing one. Is the cat missing any 'limb' or 'tail', or is it 'ok'? Simply say 'yes' or 'no'. Answer in one word by choosing one.\"],\n",
    "        [\"Image shows deepfake of a cat. Check all three before choosing one. Is any 'limb' or 'tail' disconnected from the main body, or is it 'ok'? Answer in one word by choosing one.\"],\n",
    "        [\"This is a deepfake image of a cat. Can you tell me if this image contains Anatomically incorrect paw structures? Say 'yes' or 'no'. If paw shape is not visible properly, say 'no'. Answer in one word.\"],\n",
    "        [\"This is a deepfake image of a cat. Is the head size abnormal compared to the body size? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'dog-face': [\n",
    "        [\"This is a deepfake image of a dog. Does the image contain Asymmetry in the dog's facial features? Simply say 'yes' or 'no'.  If only one side of face is visible, say 'no'. Answer in one word.\", \"Image shows deepfake of a dog. Check all four options before answering. Out of 'eyes', 'ears', 'nose', 'mouth', which one is not symmetrical? Answer in one word by choosing one.\"],\n",
    "        [\"This is a deepfake image of a dog. Are the ears like a normal dog? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [\"This is a deepfake image of a dog. Are the eyes, nose, and mouth distinguishable from each other? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'dog-body': [\n",
    "        [\"Image shows deepfake of a dog. Check all three before answering. Is the dog missing any 'limb' or 'tail', or is it 'ok'? Simply say 'yes' or 'no'. Answer in one word by choosing one.\"],\n",
    "        [\"Image shows deepfake of a dog. Check all three before answering. Is any 'limb' or 'tail' disconnected from the main body, or is it 'ok'? Answer in one word by choosing one.\"],\n",
    "        [\"This is a deepfake image of a dog. Can you tell me if this image contains Anatomically incorrect paw structures? Say 'yes' or 'no'. If paw shape is not visible properly, say 'no'. Answer in one word.\"],\n",
    "        [\"This is a deepfake image of a dog. Is the head size abnormal compared to the body size? Simply say 'yes' or 'no'.\"],\n",
    "    ],\n",
    "\n",
    "    'horse-face': [\n",
    "        [\"This is a deepfake image of a horse. Does the image contain Asymmetry in the horse's facial features? Simply say 'yes' or 'no'.  If only one side of face is visible, say 'no'. Answer in one word.\", \"Image shows deepfake of a horse. Check all four options before answering. Out of 'eyes', 'ears', 'nose', 'mouth', which one is not symmetrical? Answer in one word by choosing one.\"],\n",
    "        [\"This is a deepfake image of a horse. Are the ears like a normal horse? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [\"This is a deepfake image of a horse. Are the eyes, nose, and mouth distinguishable from each other? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'horse-body': [\n",
    "        [\"This is a deepfake image of a horse. Are the leg joints bent in an odd manner? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [\"Image shows deepfake of a horse. Check all three before choosing one. Is the dog missing any 'limb' or 'tail', or is it 'ok'? Simply say 'yes' or 'no'. Answer in one word by choosing one. Answer in one word.\"],\n",
    "        [\"Image shows deepfake of a horse. Check all three before choosing one. Is any 'limb' or 'tail' disconnected from the main body, or is it 'ok'? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [\"You are a helpful assistant. This is a deepfake image of a horse. Is the head size abnormal compared to the body size? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'deer-face': [\n",
    "        [\"This is a deepfake image of a deer. Does the image contain Asymmetry in the deer's facial features? Simply say 'yes' or 'no'. If only one side of face is visible, say 'no'. Answer in one word.\", \"Image shows deepfake of a deer. Check all four options before answering. Out of 'eyes', 'ears', 'antlers', 'nose', 'mouth', which one is not symmetrical? Answer in one word by choosing one.\"],\n",
    "        [\"This is a deepfake image of a deer. Are the 'ears' and 'antlers' both like a normal deer? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [\"This is a deepfake image of a deer. Are the eyes, nose, and mouth distinguishable from each other? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'deer-body': [\n",
    "        [\"You are a helpful assistant. This is a deepfake image of a deer. Does the image contain anatomically incorrect joint configurations? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [\"Is the deer missing any 'limb' or its 'tail', or is it 'ok'? Simply say 'yes' or 'no'.\"],\n",
    "        [\"This is a deepfake image of a deer. Is the head size abnormal compared to the body size? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'bird': [\n",
    "        [\"This is a deepfake image of a bird. If the bird's head is small, say 'no'. Otherwise, are the eyes and beak not prominent? Simply say 'yes' or 'no'. Answer in one word.\", \"You are a helpful assistant. This is a deepfake image of a bird. Can you tell me if this image contains Asymmetry in the bird's facial features? Simply say 'yes' or 'no'. If face is not visible completely, say 'no'.\", \"Image shows deepfake of a bird. Check both options before answering. Out of 'eyes' and 'beak', which one is not symmetrical? Answer in one word by choosing one.\"],\n",
    "        [\"This is a deepfake image of a bird. Does it have a blue beak? Say 'yes' or 'no'. If not visible, say 'no'. Answer in one word.\"],\n",
    "    ],\n",
    "\n",
    "    'frog': [\n",
    "        [\"This is a deepfake image of a frog. Look at the frog's hindlimbs. Is the joint configuration broken or discontinous? Simply say 'yes' or 'no'. Answer in one word.\"],\n",
    "        [\"This is a deepfake image of a frog. Is the body glossy like a metal shiny surface? Say 'yes' or 'no'. Answer in one word.\"],\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "### FROG BIG FEET\n",
    "                # \"You are a helpful assistant. This is a deepfake image of an airplane. Can you tell me if this image contains Oversized Wheels? Simply say 'yes' or 'no'.\",\n",
    "\n",
    "\n",
    "# \"You are a helpful assistant. This is a deepfake image of a cat. Cam you tell me if this image contains Abruptly cut off objects? Simply say 'yes' or 'no'.\",\n",
    "                # \"You are a helpful assistant. This is a deepfake image of an airplane. Cam you tell me if this image contains Non Manifold Geometries ? Simply say 'yes' or 'no'.\",\n",
    "                # \"You are a helpful assistant. This is a deepfake image of an airplane. Cam you tell me if this image contains Impossible Mechanical Connections? Simply say 'yes' or 'no'.\"\n",
    " \n",
    "\n",
    "# \"Describe the oddest color in the {animal}\"\n",
    "# \"Are the surroundings dark but the {object} still shining? Say 'yes' or 'no'.\", --> Unrealistic Specular Highlights\n",
    "\n",
    "#\"You are a helpful assistant. This is a deepfake image of a cat. Cam you tell me if this image contains Anatomically incorrect paw structures? Simply say 'yes' or 'no'.\",\\\n",
    "\n",
    "#    \"You are a helpful assistant. This is a deepfake image of a truck. Can you tell me if this image contains Inconsistent Scale of Mechanical Parts? Simply say 'yes' or 'no'.\"],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba14edd-a1c0-47f8-a7b2-40e776d0e39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "def evaluate_img(image_path, annotated_image_path, index):\n",
    "    image = Image.open(image_path)\n",
    "    annotated_image = Image.open(annotated_image_path)\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (6, 3))\n",
    "    ax[0].imshow(image)\n",
    "    ax[1].imshow(annotated_image)\n",
    "    plt.show()\n",
    "\n",
    "    obj = classify_obj(image)\n",
    "    print(obj)\n",
    "    \n",
    "    artifacts = []\n",
    "    for prompt in common_prompts:\n",
    "         ans = extract_ans(prompt, image, obj, index)\n",
    "        # st.append(extracted_sentence)\n",
    "    if obj != 'others':\n",
    "        if obj in ['cat', 'deer', 'dog', 'horse']:\n",
    "            ans = extract_ans(animal_prompts[0], annotated_image, obj, -1).lower()\n",
    "    \n",
    "            if ans == \"face\":\n",
    "                is_face = True\n",
    "            else:\n",
    "                is_face = False\n",
    "                \n",
    "            for i in range(1, len(animal_prompts)):\n",
    "                ans = extract_ans(animal_prompts[i], image, obj, index)\n",
    "            \n",
    "            if is_face == True:\n",
    "                class_prompts = prompts[f'{obj}-face']\n",
    "            else:\n",
    "                class_prompts = prompts[f'{obj}-body']\n",
    "        else:\n",
    "            class_prompts = prompts[f'{obj}']\n",
    "            \n",
    "        for prompt in class_prompts:\n",
    "            ans = extract_ans(prompt, image, obj, index)    \n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79a14081-46b4-46df-8307-b184e26f4c25",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fake_indices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m fake_indices:\n\u001b[1;32m      2\u001b[0m     image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/temp/super_res/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m     annotated_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput/temp/grad_cam/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fake_indices' is not defined"
     ]
    }
   ],
   "source": [
    "for i in fake_indices:\n",
    "    image_path = f\"output/temp/super_res/{i}.png\"\n",
    "    annotated_image_path = f\"output/temp/grad_cam/{i}.png\"\n",
    "    evaluate_img(image_path, annotated_image_path, i)\n",
    "    # print(json_data)\n",
    "\n",
    "# Save to a JSON file\n",
    "output_json_file = 'output/84_task2.json'\n",
    "with open(output_json_file, 'w') as file:\n",
    "    json.dump(json_data, file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83c6bb2-8d2b-42a1-b6a9-90b41ff22e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "# # for i in range(1, 10): \n",
    "# image_path = f\"sr_4 (2).jpg\"\n",
    "# image = Image.open(image_path)\n",
    "# # annotated_image_path = f\"grad/{i}_grad.jpg\" \n",
    "# # annotated_image = Image.open(annotated_image_path)\n",
    "# # class = classifier(image_path)\n",
    "# # prompt = prompts[class]\n",
    "# # print(class)\n",
    "# # print(prompt)\n",
    "\n",
    "# messages = [\n",
    "#     {\"role\": \"user\", \"content\": [\n",
    "#         {\"type\": \"image\"},\n",
    "#       #  {\"type\": \"text\", \"text\": \"Is the heatmap red part concentrated on the 'face','body' or 'background'? Answer in one word.\"}\n",
    "#         {\"type\": \"text\", \"text\": \"You are a helpful assistant. This is a deepfake image of a car. Can you tell me if this image contains Misaligned Body Panels? Simply say 'yes' or 'no'. \"}\n",
    "#     ]}\n",
    "# ]\n",
    "# input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "# # Process the input, ensure the inputs are on the same device as the model\n",
    "# inputs = processor(\n",
    "#     image,\n",
    "#     input_text,\n",
    "#     add_special_tokens=False,\n",
    "#     return_tensors=\"pt\"\n",
    "# ).to(model.device)\n",
    "\n",
    "# # Generate output from the model\n",
    "# output = model.generate(**inputs, max_new_tokens=10)\n",
    "# text = processor.decode(output[0])\n",
    "# # start = text.find('<|end_header_id|>') + len('<|end_header_id|>')\n",
    "# # end = text.find('<|eot_id|>')\n",
    "\n",
    "# # extracted_sentence = text[start:end].strip()\n",
    "\n",
    "# print(text)#extracted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a0a26c1-f9ec-49af-951c-2eb9196b631e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image output/temp/Foreground/foreground_1.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_5.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_23.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_24.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_29.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_30.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_31.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_33.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_37.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_51.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_55.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_69.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_94.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_98.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_102.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_110.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_118.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_123.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_128.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_137.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_150.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_151.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_152.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_157.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_160.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_162.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_167.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_175.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_176.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_177.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_178.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_185.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_190.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_191.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_199.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_208.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_211.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_213.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_220.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_222.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_225.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_232.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_237.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_239.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_250.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_256.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_257.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_276.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_278.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_283.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_284.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_293.png: Oversmoothened background detected.\n",
      "Image output/temp/Foreground/foreground_294.png: Oversmoothened background detected.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "def image_black(image):\n",
    "    \"\"\"\n",
    "    Detect if the background of an image transitions smoothly from one color to another (gradient).\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): Path to the input image.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if a gradient is detected, False otherwise.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    # image = cv2.imread(image_path)\n",
    "    # if image is None:\n",
    "    #     raise ValueError(\"Image not found or unable to load.\")\n",
    "\n",
    "\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Step 2: Invert the grayscale image (255 - pixel values)\n",
    "    inverted_image = 255 - gray_image\n",
    "\n",
    "    # Step 3: Take the exponential of the pixel values\n",
    "    # Normalize to the range [0, 1], apply exponential, then scale back to [0, 255]\n",
    "    exp_image = np.exp(inverted_image / 255.0)/np.e  # Apply exp after normalizing\n",
    "    exp_image = (exp_image > 0.9)\n",
    "    orig_mask = 1 - exp_image\n",
    "    orig_mask = np.clip(orig_mask * 255.0, 0, 255).astype('uint8')\n",
    "    # orig_mask = Image.fromarray(orig_mask)\n",
    "    # orig_mask.show()\n",
    "\n",
    "    three_channel_mask = cv2.cvtColor(orig_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    # Step 3: Mask the RGB image using the grayscale mask (keep pixels where mask is non-zero)\n",
    "    masked_rgb_image = cv2.bitwise_and(image, three_channel_mask)\n",
    "\n",
    "    # Image.fromarray(masked_rgb_image).show()\n",
    "\n",
    "    image = masked_rgb_image\n",
    "    return image\n",
    "\n",
    "def analyze_image(actual_path, image_path, gradient_threshold=20, black_threshold=30):\n",
    "    \"\"\"\n",
    "    Analyze an image to find the number of background pixels (non-black regions)\n",
    "    and compute the sum of a mask where the gradient is below a threshold.\n",
    "\n",
    "    Parameters:\n",
    "        image_path (str): Path to the input image.\n",
    "        gradient_threshold (int): Threshold for the gradient magnitude.\n",
    "        black_threshold (int): Tolerance for RGB values to classify a pixel as \"black.\"\n",
    "\n",
    "    Returns:\n",
    "        background_pixel_count (int): Number of non-black pixels.\n",
    "        gradient_mask_sum (int): Sum of the gradient mask values (pixels below threshold).\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    act_image = cv2.imread(actual_path)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image not found or unable to load.\")\n",
    "    height, width = image.shape[:2]\n",
    "    crop_pixels = 2\n",
    "    image = image[crop_pixels:height-crop_pixels, crop_pixels:width-crop_pixels]\n",
    "    image = image_black(image)\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Identify non-black pixels\n",
    "    non_black_mask = np.any(image > 0, axis=-1)  # Non-black pixels across RGB channels\n",
    "    non_black_count = np.sum(non_black_mask)\n",
    "\n",
    "\n",
    "    # Compute the gradient in the x and y directions\n",
    "    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)  # Gradient in x-direction\n",
    "    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)  # Gradient in y-direction\n",
    "\n",
    "    # Compute the magnitude of the gradient\n",
    "    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)\n",
    "\n",
    "    # Normalize the gradient magnitude to range 0-255\n",
    "    gradient_normalized = cv2.normalize(gradient_magnitude, None, 0, 255, cv2.NORM_MINMAX)\n",
    "\n",
    "    # Create the mask: 1 if gradient < gradient_threshold, 0 otherwise\n",
    "    # Find pixels below threshold among non-black pixels\n",
    "    gradient_mask = (gradient_normalized < gradient_threshold) & non_black_mask\n",
    "    gradient_mask_sum = np.sum(gradient_mask)\n",
    "\n",
    "    # # Display the results\n",
    "    # plt.figure(figsize=(15, 10))\n",
    "    # plt.subplot(1, 3, 1)\n",
    "    # plt.title(\"Original Image\")\n",
    "    # plt.imshow(cv2.cvtColor(act_image, cv2.COLOR_BGR2RGB))\n",
    "    # plt.axis(\"off\")\n",
    "\n",
    "    # plt.subplot(1, 3, 2)\n",
    "    # plt.title(\"Non-Black Mask\")\n",
    "    # plt.imshow(non_black_mask, cmap='gray')\n",
    "    # plt.axis(\"off\")\n",
    "\n",
    "    # plt.subplot(1, 3, 3)\n",
    "    # plt.title(f\"Gradient Mask (Threshold={gradient_threshold})\")\n",
    "    # plt.imshow(gradient_mask * 255, cmap='gray')\n",
    "    # plt.axis(\"off\")\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    return non_black_count, gradient_mask_sum\n",
    "# Save updated JSON with appended explanations\n",
    "gradient_threshold = 20  # Gradient threshold\n",
    "black_threshold = 30     # Black pixel threshold\n",
    "oversmooth_threshold = 0.45\n",
    "\n",
    "json_file_path = \"output/84_task2.json\"  # Replace with your JSON file path\n",
    "with open(json_file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Process each entry in the JSON\n",
    "for entry in data:\n",
    "    i = entry[\"index\"]\n",
    "    image_path = f\"output/temp/Foreground/foreground_{i}.png\"\n",
    "    actual_path = f\"output/temp/super_res/{i}.png\"\n",
    "\n",
    "    # Analyze the image\n",
    "    background_pixel_count, gradient_mask_sum = analyze_image(actual_path, image_path, gradient_threshold, black_threshold)\n",
    "    ratio = gradient_mask_sum / background_pixel_count\n",
    "\n",
    "    if ratio > oversmooth_threshold:\n",
    "        print(f\"Image {image_path}: Oversmoothened background detected.\")\n",
    "        # Initialize explanation if it doesn't exist\n",
    "        if \"explanation\" not in entry:\n",
    "            entry[\"explanation\"] = {}\n",
    "\n",
    "        # Add or update the explanation for artificial smoothness\n",
    "        entry[\"explanation\"][\"Artificial smoothness\"] = \"The background exhibits a high degree of smoothing with minimal gradients.\"\n",
    "\n",
    "# Save the updated JSON\n",
    "with open(json_file_path, \"w\") as file:\n",
    "    json.dump(data, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3084d29-eebd-45e7-91c1-3649679d60ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
